{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca0a582",
   "metadata": {},
   "source": [
    "#### Let's preprocess each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "46e9288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "d6ed04e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/processed/preprocessed_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "aa6ca9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 100.0\n",
      "Min: 6.0\n"
     ]
    }
   ],
   "source": [
    "acceptance_rate_max = df['acceptance_rate_clean'].max(skipna=True)\n",
    "acceptance_rate_min = df['acceptance_rate_clean'].min(skipna=True)\n",
    "\n",
    "print(\"Max:\", acceptance_rate_max)\n",
    "print(\"Min:\", acceptance_rate_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "602ae309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['undergrad_gpa'] = pd.to_numeric(df['undergrad_gpa'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "591d99e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 332.0\n",
      "Min: 0.01\n"
     ]
    }
   ],
   "source": [
    "undergrad_gpa_max = df['undergrad_gpa'].max(skipna=True)\n",
    "undergrad_gpa_min = df['undergrad_gpa'].min(skipna=True)\n",
    "\n",
    "print(\"Max:\", undergrad_gpa_max)\n",
    "print(\"Min:\", undergrad_gpa_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "80eed7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa_greater_than_equal_to_one = df.undergrad_gpa >= 1.0\n",
    "gpa_less_than_equal_to_four = df.undergrad_gpa <= 4.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f419dbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44138"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_gpa_profiles = df[gpa_greater_than_equal_to_one & gpa_less_than_equal_to_four]\n",
    "len(valid_gpa_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "1350bf80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56488"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_gpa_profiles = df[~(gpa_greater_than_equal_to_one & gpa_less_than_equal_to_four)]\n",
    "len(invalid_gpa_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5ffc66",
   "metadata": {},
   "source": [
    "#### Sometimes the user may enter the gpa without the '.', hence we should check if someone has entered values between 100 to 332(since 332 is the vax value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "9399e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa_greater_than_equal_to_hundred = df['undergrad_gpa'] >= 100\n",
    "gpa_less_than_equal_to_three_three_three = df['undergrad_gpa'] < 333\n",
    "valid_gpa_profiles_above_hundred = df[gpa_greater_than_equal_to_hundred & gpa_less_than_equal_to_three_three_three]\n",
    "valid_gpa_profiles_above_hundred\n",
    "condition = (df['undergrad_gpa'] >= 100) & (df['undergrad_gpa'] < 332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "00ca573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['undergrad_gpa'] = df['undergrad_gpa'].mask(df['undergrad_gpa'] == condition, df['undergrad_gpa'] / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "4a1ce3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_gpa_profiles_above_hundred = df[gpa_greater_than_equal_to_hundred & gpa_less_than_equal_to_three_three_three]\n",
    "len(valid_gpa_profiles_above_hundred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd49ca1",
   "metadata": {},
   "source": [
    "### The GRE General Test has three scored sections, each with its own score range:\n",
    "\n",
    "#### Verbal Reasoning : Score range: 130 to 170\n",
    "\n",
    "#### Quantitative Reasoning : Score range: 130 to 170\n",
    "\n",
    "#### Analytical Writing : Score range: 0 to 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "7171974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gre_general'] = pd.to_numeric(df['gre_general'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "768d3a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10687"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gre_score_general_min = df['gre_general'] >= 130.0\n",
    "gre_score_general_max = df['gre_general'] <= 170.0\n",
    "valid_gre_general_profiles = df[gre_score_general_min & gre_score_general_max]\n",
    "len(valid_gre_general_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a68e3",
   "metadata": {},
   "source": [
    "### Approach\n",
    "Maybe a person entered their entire score instead of gre general. In that case the score boundary should be within 260 to 340. Else if it exceeds that then the same is neglected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6288c886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_gre_general_profiles = df[~(gre_score_general_min & gre_score_general_max) & ~df['gre_general'].isna()]\n",
    "len(invalid_gre_general_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656ca55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3         False\n",
       "4         False\n",
       "          ...  \n",
       "100621    False\n",
       "100622    False\n",
       "100623    False\n",
       "100624    False\n",
       "100625    False\n",
       "Name: gre_general, Length: 100626, dtype: bool"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gre_general_wrong_assigned_valid_scores = (df['gre_general'] >= 260) & (df['gre_general'] <= 340)\n",
    "len(gre_general_wrong_assigned_valid_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf5477",
   "metadata": {},
   "source": [
    "#### Assigning values from 260 to 340 to gre_total column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3f137f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gre_total'] = df.loc[(df['gre_general'] >= 260) & (df['gre_general'] <= 340), 'gre_general']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c291c",
   "metadata": {},
   "source": [
    "#### Removing values from 260 to 340 to gre_total column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "65dd62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['gre_general'] >= 260) & (df['gre_general'] <= 340), 'gre_general'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "759eae7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1379"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_gre_general_profiles = df[~(gre_score_general_min & gre_score_general_max) & ~df['gre_general'].isna()]\n",
    "len(invalid_gre_general_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1fc69d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10687"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gre_score_verbal_min = df['gre_general'] >= 130\n",
    "gre_score_verbal_max = df['gre_general'] <= 170\n",
    "valid_gre_verbal_profiles = df[gre_score_verbal_min & gre_score_verbal_max]\n",
    "len(valid_gre_verbal_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "1e4e120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (df['undergrad_gpa'] >= 130) & (df['undergrad_gpa'] < 171)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7c07f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gre_verbal'] = pd.to_numeric(df['gre_verbal'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "31b6adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gre_score_general_min = df['gre_verbal'] >= 130\n",
    "gre_score_general_max = df['gre_verbal'] <= 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cb68b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['analytical_writing'] = pd.to_numeric(df['analytical_writing'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "33d9d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gre_analytical_writing_min = df['analytical_writing'] >= 0.0\n",
    "gre_analytical_writing_max = df['analytical_writing'] >= 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb068c7",
   "metadata": {},
   "source": [
    "### Correlation between different variables and their visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "466c5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert relevant fields\n",
    "df['decision_encoded'] = df['decision'].map({\n",
    "    'Accepted': 1,\n",
    "    'Rejected': 0,\n",
    "    'Interview': 0.5,  # optional: if you want to include partial decision stages\n",
    "    'Waitlisted': 0.25,\n",
    "    'Other': None\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ea582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
