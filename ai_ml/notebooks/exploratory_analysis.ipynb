{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca0a582",
   "metadata": {},
   "source": [
    "#### Let's preprocess each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1959,
   "id": "46e9288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674023ae",
   "metadata": {},
   "source": [
    "### Reading the excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1960,
   "id": "d6ed04e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/processed/preprocessed_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1961,
   "id": "a8c4f827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'acceptance_rate', 'institution', 'program', 'degree_type',\n",
       "       'decision', 'undergrad_gpa', 'gre_quantitative_reasoning',\n",
       "       'gre_verbal_reasoning', 'analytical_writing', 'notes', 'gre_total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63436f8c",
   "metadata": {},
   "source": [
    "### Checking the maximum and minimum acceptance rate range to see whether it is valid or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1962,
   "id": "9fed568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['acceptance_rate'] = pd.to_numeric(df['acceptance_rate'].str.replace('%', ''), errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1963,
   "id": "aa6ca9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 100.0\n",
      "Min: 6.0\n"
     ]
    }
   ],
   "source": [
    "acceptance_rate_max = df['acceptance_rate'].max(skipna=True)\n",
    "acceptance_rate_min = df['acceptance_rate'].min(skipna=True)\n",
    "\n",
    "print(\"Max:\", acceptance_rate_max)\n",
    "print(\"Min:\", acceptance_rate_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b7aaeb",
   "metadata": {},
   "source": [
    "### Since the range is between 6% to 100%, the acceptance rate data seems fairly valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaccd906",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ceb0d",
   "metadata": {},
   "source": [
    "### Converting the gpa to numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1964,
   "id": "602ae309",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['undergrad_gpa'] = pd.to_numeric(df['undergrad_gpa'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240bba5",
   "metadata": {},
   "source": [
    "### Checking the range of maximum and mininum of gpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1965,
   "id": "591d99e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 332.0\n",
      "Min: 0.01\n"
     ]
    }
   ],
   "source": [
    "undergrad_gpa_max = df['undergrad_gpa'].max(skipna=True)\n",
    "undergrad_gpa_min = df['undergrad_gpa'].min(skipna=True)\n",
    "\n",
    "print(\"Max:\", undergrad_gpa_max)\n",
    "print(\"Min:\", undergrad_gpa_min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8643611",
   "metadata": {},
   "source": [
    "### Valid GPA case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1966,
   "id": "f419dbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44138"
      ]
     },
     "execution_count": 1966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpa_greater_than_equal_to_one = df['undergrad_gpa'] >= 1.0\n",
    "gpa_less_than_equal_to_four = df['undergrad_gpa'] <= 4.0\n",
    "valid_gpa_between_one_and_four = df[gpa_greater_than_equal_to_one & gpa_less_than_equal_to_four]\n",
    "len(valid_gpa_between_one_and_four)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f3a78f",
   "metadata": {},
   "source": [
    "### Valid GPA Case 2\n",
    "##### Sometimes the user may enter the gpa without the '.', hence we should check if someone has entered values between 100 to 332(since 332 is the vax value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1967,
   "id": "6575c709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>acceptance_rate</th>\n",
       "      <th>institution</th>\n",
       "      <th>program</th>\n",
       "      <th>degree_type</th>\n",
       "      <th>decision</th>\n",
       "      <th>undergrad_gpa</th>\n",
       "      <th>gre_quantitative_reasoning</th>\n",
       "      <th>gre_verbal_reasoning</th>\n",
       "      <th>analytical_writing</th>\n",
       "      <th>notes</th>\n",
       "      <th>gre_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23246</th>\n",
       "      <td>965397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of California</td>\n",
       "      <td>Informatics</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Accepted</td>\n",
       "      <td>332.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>interviewed on 1/28</td>\n",
       "      <td>Acceptance</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  acceptance_rate               institution      program  \\\n",
       "23246  965397              NaN  University of California  Informatics   \n",
       "\n",
       "      degree_type  decision  undergrad_gpa  gre_quantitative_reasoning  \\\n",
       "23246         PhD  Accepted          332.0                         NaN   \n",
       "\n",
       "       gre_verbal_reasoning   analytical_writing       notes  gre_total  \n",
       "23246                   NaN  interviewed on 1/28  Acceptance        NaN  "
      ]
     },
     "execution_count": 1967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpa_greater_than_equal_to_hundred = df['undergrad_gpa'] >= 100\n",
    "gpa_less_than_equal_to_four_hundred = df['undergrad_gpa'] < 401\n",
    "valid_gpa_between_one_hundred_and_below_four_hundred = df.loc[(gpa_greater_than_equal_to_hundred) & (gpa_less_than_equal_to_four_hundred)]\n",
    "valid_gpa_between_one_hundred_and_below_four_hundred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1968,
   "id": "88baa086",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = gpa_greater_than_equal_to_hundred & gpa_less_than_equal_to_four_hundred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1969,
   "id": "09b856dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[condition, 'undergrad_gpa'] = df.loc[condition, 'undergrad_gpa'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1970,
   "id": "1eb27957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresh_mask = (df['undergrad_gpa'] >= 100) & (df['undergrad_gpa'] <= 400)\n",
    "len(df.loc[fresh_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa31902",
   "metadata": {},
   "source": [
    "### Invalid GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1971,
   "id": "0c17f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Identify invalid GPA entries\n",
    "invalid_gpa_mask = (\n",
    "    (df['undergrad_gpa'] < 1.0) |\n",
    "    (df['undergrad_gpa'] > 4.0) |  # You probably meant 4.0, not 400\n",
    "    (df['undergrad_gpa'].isna())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1972,
   "id": "223f59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Generate random GPAs in a realistic range (around 3.8)\n",
    "random_gpas = np.clip(\n",
    "    np.random.normal(loc=3.8, scale=0.1, size=invalid_gpa_mask.sum()),\n",
    "    3.6, 4.0\n",
    ")\n",
    "\n",
    "# Step 3: Replace invalid entries with these generated values\n",
    "df.loc[invalid_gpa_mask, 'undergrad_gpa'] = random_gpas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1973,
   "id": "25c07af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['undergrad_gpa'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5706d",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd49ca1",
   "metadata": {},
   "source": [
    "### The GRE General Test has three scoring sections, each with its own score range:\n",
    "\n",
    "#### Verbal Reasoning : Score range: 130 to 170\n",
    "\n",
    "#### Quantitative Reasoning : Score range: 130 to 170\n",
    "\n",
    "#### Analytical Writing : Score range: 0 to 6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1974,
   "id": "7171974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert GRE scores to numeric\n",
    "list_of_gre_columns = ['gre_quantitative_reasoning', 'gre_verbal_reasoning']\n",
    "df[list_of_gre_columns[0]] = pd.to_numeric(df[list_of_gre_columns[0]], errors = 'coerce')\n",
    "df[list_of_gre_columns[1]] = pd.to_numeric(df[list_of_gre_columns[1]], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1975,
   "id": "768d3a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10687"
      ]
     },
     "execution_count": 1975,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gre_quantitative_reasoning_min = df[list_of_gre_columns[0]] > 129.0\n",
    "gre_quantitative_reasoning_max = df[list_of_gre_columns[0]] < 171.0\n",
    "valid_gre_quantitative_reasoning_profiles = df[gre_quantitative_reasoning_min & gre_quantitative_reasoning_max]\n",
    "len(valid_gre_quantitative_reasoning_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1976,
   "id": "8f05873a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10687"
      ]
     },
     "execution_count": 1976,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gre_verbal_reasoning_min = df[list_of_gre_columns[1]] > 129.0\n",
    "gre_verbal_reasoning_max = df[list_of_gre_columns[1]] < 171.0\n",
    "valid_gre_quantitative_reasoning_profiles = df[gre_quantitative_reasoning_min & gre_quantitative_reasoning_max]\n",
    "len(valid_gre_quantitative_reasoning_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a68e3",
   "metadata": {},
   "source": [
    "### Approach\n",
    "Maybe a person entered their entire score instead of gre general. In that case the score boundary should be within 260 to 340. Else if it exceeds that then the same is neglected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1977,
   "id": "6288c886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1568"
      ]
     },
     "execution_count": 1977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_gre_quantitative_reasoning_profiles = df[~(gre_quantitative_reasoning_min & gre_quantitative_reasoning_max) & ~df[list_of_gre_columns[0]].isna()]\n",
    "len(invalid_gre_quantitative_reasoning_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1978,
   "id": "e59b916c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 1978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_gre_verbal_reasoning_profiles = df[~(gre_verbal_reasoning_min & gre_verbal_reasoning_max) & ~df[list_of_gre_columns[1]].isna()]\n",
    "len(invalid_gre_verbal_reasoning_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecf5477",
   "metadata": {},
   "source": [
    "#### Assigning values from 260 to 340 to gre_total column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1979,
   "id": "3f137f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gre_total'] = df.loc[(df[list_of_gre_columns[0]] >= 260) & (df[list_of_gre_columns[0]] <= 340), list_of_gre_columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1980,
   "id": "b388c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gre_total'] = df.loc[(df[list_of_gre_columns[1]] >= 260) & (df[list_of_gre_columns[1]] <= 340), list_of_gre_columns[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c291c",
   "metadata": {},
   "source": [
    "#### Removing values 260 to 340 from gre_general column to gre_total column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1981,
   "id": "65dd62bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[list_of_gre_columns[0]] >= 260) & (df[list_of_gre_columns[0]] <= 340), list_of_gre_columns[0]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1982,
   "id": "47f034db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df[list_of_gre_columns[1]] >= 260) & (df[list_of_gre_columns[1]] <= 340), list_of_gre_columns[1]] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760ead6d",
   "metadata": {},
   "source": [
    "### Re-checking if there are any values between 260 and 340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1983,
   "id": "a89b3894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[(df[list_of_gre_columns[0]] >= 260) & (df[list_of_gre_columns[0]] <= 340)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1984,
   "id": "62ce54fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1984,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[(df[list_of_gre_columns[1]] >= 260) & (df[list_of_gre_columns[1]] <= 340)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc56a0",
   "metadata": {},
   "source": [
    "### Checking rows with values :\n",
    "#### Below 130 \n",
    "#### Above 340\n",
    "#### Between 170 to 260"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107e2de9",
   "metadata": {},
   "source": [
    "#### Checking for quantitative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1985,
   "id": "42443874",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[list_of_gre_columns[0]] = pd.to_numeric(df[list_of_gre_columns[0]], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024cbfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88370"
      ]
     },
     "execution_count": 1993,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[list_of_gre_columns[0]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1994,
   "id": "51227a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12255"
      ]
     },
     "execution_count": 1994,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(~df[list_of_gre_columns[0]].isna()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1995,
   "id": "32d51c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid rows for ['gre_quantitative_reasoning', 'gre_verbal_reasoning']: 12255\n"
     ]
    }
   ],
   "source": [
    "rows_above_340_gre_quantitative_reasoning = (\n",
    "    (df[list_of_gre_columns[0]] > 340) |\n",
    "    (df[list_of_gre_columns[0]] < 130) |\n",
    "    (df[list_of_gre_columns[0]] >= 170) |\n",
    "    (df[list_of_gre_columns[0]] < 260)  # This overlaps with < 130 and < 170\n",
    ").sum()\n",
    "\n",
    "print(f\"Invalid rows for {list_of_gre_columns}: {rows_above_340_gre_quantitative_reasoning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fdd348",
   "metadata": {},
   "source": [
    "#### Checking for verbal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1987,
   "id": "43f3c6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 1987,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_above_340_gre_verbal_reasoning = (df[list_of_gre_columns[1]] >= 260).sum()\n",
    "rows_above_340_gre_verbal_reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78fdde",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1988], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[df[list_of_gre_columns[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m260\u001b[39m]]\n",
      "\u001b[0;31mTypeError\u001b[0m: '>' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "# df.loc[df[list_of_gre_columns[0] > 260]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14bbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gre_quantitative_reasoning_above_170_and_below_260 = df.loc[(df['gre_quantitative_reasoning'] > 170) & (df['gre_quantitative_reasoning'] < 260), 'gre_quantitative_reasoning']\n",
    "len(gre_quantitative_reasoning_above_170_and_below_260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.to_numeric(df['gre_verbal_reasoning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b963a1",
   "metadata": {},
   "source": [
    "### Checking valid GRE Verbal scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef3cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc69d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gre_score_verbal_max'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1842], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgre_score_verbal_max\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'gre_score_verbal_max'"
     ]
    }
   ],
   "source": [
    "df['gre_score_verbal_max'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (df['undergrad_gpa'] >= 130) & (df['undergrad_gpa'] < 171)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c07f709",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gre_verbal'] = pd.to_numeric(df['gre_verbal'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b6adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gre_score_general_min = df['gre_verbal'] >= 130\n",
    "gre_score_general_max = df['gre_verbal'] <= 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb68b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['analytical_writing'] = pd.to_numeric(df['analytical_writing'], errors = 'coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d9d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gre_analytical_writing_min = df['analytical_writing'] >= 0.0\n",
    "gre_analytical_writing_max = df['analytical_writing'] >= 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb068c7",
   "metadata": {},
   "source": [
    "### Correlation between different variables and their visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c5616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert relevant fields\n",
    "df['decision_encoded'] = df['decision'].map({\n",
    "    'Accepted': 1,\n",
    "    'Rejected': 0,\n",
    "    'Interview': 0.5,  # optional: if you want to include partial decision stages\n",
    "    'Waitlisted': 0.25,\n",
    "    'Other': None\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ea582",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
